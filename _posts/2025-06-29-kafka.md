---
layout: post
title: "Kafka"
subtitle: ""
tags: ["system-design"]
readtime: true
---

In the previous post, we looked at what async messaging is, why is it needed, and how we can leverage message brokers for async communication. Imagine that you are developing a video ingestion application such that when a creator submits a video, you want to do two things:
- Index it in your search index DB
- Update the analytics DB with stats on how many videos has the creator published, how many minutes has the creator published, etc

If you are using message brokers, you'll have to use two queues bound to a topic exchange as if you connect two separate consumers to a single queue, each messages is delivered to only one of them. The issue with using two queues is that:
1. Each message is getting duplicated in both queues
2. If one queue is temporarily unavailable, the message only makes it to one of the queues. In our example, it can mean that the analytics DB got updated but the search index doesn't have any record of the video. This is a nightmare for the creators and the developers as well.

What we want here is a "publish to one, consumed by many" paradigm where the producer only publishes to one queue but multiple consumers can read from the queue. It would ensure that if a message is dropped, it is dropped for all consumers. Events Streams (also called Message Streams) enable us to achieve this. 

An event stream or a message stream is simply a real-time sequence of events (small discrete messages), like a log that keeps appending new entries as they come. One of the most commonly used Events Streams is Apache Kafka. It is a distributed event streaming platform developed by LinkedIn originalyy and later open sourced. You can think of Kafka as a distributed commit log where each new event is written at the end, and multiple clients can read the log at their own pace.

## Kafka 101: Core Concepts

As we did with RabbitMQ, the best way to understand terminology is to take a bird's eye view of how producers and consumers write and read from Kafka:
1. A producer publishes an event to a topic. Topics are different categories where events go. More formally, they are named streams of events, e.g., `user-signups`.
2. Kafka splits each topic into smaller pieces called partitions, which are ordered and immutable. Kafka writes each message/event sent to a topic in one of the topics's partitions. Every event in a partition gets a number called an offset, which is just a way of Kafka to track the messages in the partition.
3. A partition can be read by different consumers, each consuming the partition at its own pace. Kafka uses the offsets to track which message each consumer consumed last.

Let‚Äôs walk through a simple example: You're building a food delivery app like DoorDash.
1. User places an order -> Your backend app creates an event like `OrderPlaced`.
2. The app is a producer -> it sends the event to Kafka‚Äôs `orders` topic.
3. Kafka stores the event in one of the topic‚Äôs partitions.
4. Your consumer app (maybe a notification service) reads the `OrderPlaced` event.
5. It processes the event (e.g., sends a confirmation text). Kafka keeps the event stored even after it‚Äôs read, so another consumer (like an analytics service) can also read it later.

The Kafka server that stores events and handles requests is called the Broker.

From the consumer perspective, a consumer service subscribes to a topic and not a partition - it is assigned a partition by the Kafka broker. In a distributed system, you typically have multiple replicas of each service, let's say the notificitation service. When each replica of the notification service connects to Kafka, it tells Kafka *"Hey! I want to connect to `orders` topic and I belong to `notifications` consumer group"*. By design, Kafka will allow only one consumer of a consumer group to consume from a partition of any topic. This means that each replica of our notification service consumes from a different partition of the `orders` topic. This ensures that each message is only consumed once per consumer group. 

Let's look the some scenarios:
1. If the number of consumers in a consumer group is the same as the number of partitions in a topic, each consumer gets assigned one partition.
2. If the number of consumers in a consumer group is less than the number of partitions in a topic, some consumers will get assigned more than one partition. This maintains full coverage of events, but leads to uneven load. 
3. If the number of consumers in a consumer group is more than the number of partitions in a topic, some consumers will get assigned one partition and some consumers will stay idle.

Kafka ensures no duplication within a consumer group (the same message is not read by different consumers within a consumer group) and parallelism across partitions (different replicas are subscribed to different partitions).

## Kafka Offsets

An offset is just a number that marks the position of a message in a Kafka partition. Each partition can be thought of as an append-only-log file. An offset is the position of an event in this log file. So the first event in a partition gets assigned an offset of 0, the second message gets assigned an offset of 1, and so on. This offset is immutable, that is, messages never change place. Offsets are used by the consumer and the kafka to decide which message the consumer is supposed to read next.

> üìù Note: Unlike RabbitMQ, which supports both push and pull based consumption, Kafka is strictly pull-based. This design enables different consumer groups to consumer at their own pace from the same partition, enables Kafka to support batching, allows consumers to re-read old data by seeking back to older offsets, and improves scalability of Kafka as it doesn't have to manage queues and delivery state per consumer.

### How Kafka Stores Offsets (Under the Hood)

Kafka gives consumers two options for managing offsets:

#### 1. Consumer commits the offset to Kafka itself (default)
In this mode, Kafka stores the offsets in a special internal topic called `__consumer_offsets`. This topic is replicated, durable, and compacted (we'll see what it means) and offsets are stored per consumer group, per topic-partition. Offset commits are just special messages in the `__consumer_offsets` topic. For example: For a consumer from the consumer group `notifications`, consuming from the 3rd partition in the topic `orders`, if the last read message has an offset of 105, Kafka stores: "notifications has read up to offset 105 in orders[3]"

Now, if everything is running smoothly (no consumer restarts, no partition reassignments, etc), the consumer itself tracks the offsets in memory and which partition it is assigned to (this is implemented by the kafka client libraries). Each time it wants to read from Kafka, it asks *"Give me messages starting from offset `106`"*. Kafka will respond with messages: `106`, `107`, `108`, ...

> üìù Note: Kafka supports batch fetching, and it‚Äôs a key feature for performance and efficiency. Instead of asking for one message at a time, a Kafka consumer can request a batch of messages in a single fetch request. Batch fetching is the default and recommended behavior in Kafka consumers for efficiency and throughput.

In the case of an application restart (Reboot / Crash Recovery), Kafka uses the offsets it stored in `__consumer_offsets` to tell the consumer *"Hey, your last known position was `105`. Start from `106`."* Consumers fetch committed offsets using a lightweight request to Kafka brokers.

| Function                                                        | Who Handles It                | Where It Lives                              |
| --------------------------------------------------------------- | ----------------------------- | ------------------------------------------- |
| **Track current offset** (as you fetch new messages)            | Kafka consumer client         | In memory (no code from you needed)         |
| **Store committed offset** (so you can recover after a restart) | Kafka + client (configurable) | Kafka's internal topic `__consumer_offsets` |

#### 2. Consumer stores offsets externally
In most modern systems, Kafka‚Äôs internal offset management is the go-to choice. But the consumer can choose to handle everything on their side. To accomplish this, consumers will have to store offsets for each consumer group per topic-partition in some external DB like Redis, MySQL, etc.


### How Offsets Are Committed

Consumers again have two choices when it to comes to when to commit offsets:

#### 1. Automatic commit
Kafka Broker will periodically commit the offsets per consumer group per topic-partition periodically (default every 5 seconds). This means:
- If the consumer crashes while processing a message and the Kafka periodic commit happens during this time, the consumer won't get the message again
- If the consumer crashes after processing a message but before Kafka periodic commit happens, the consumer will have to reconsume the message it has already processed

This is not the best choice for critical or idempotent systems.

#### 2. Manual commit
In this mode, the consumer commits offsets only after successful processing. It gives more control, especially for avoiding message loss or duplication.

### Offset and Rebalancing

Kafka reassigns partitions in the following scenarios:
- Consumer application crashes or is restarted
- A new consumer joins the group
- A consumer leaves the group
- A heartbeat timeout occurs (the consumer is slow or paused)

In any of the above scenarios, Kafka will have to rebalance the group. This means that the partitions of the topics being consumed by the consumer group get reassigned, and consumers may take over partitions they weren‚Äôt handling before. Kafka offsets allow the consumers to resume from the last committed offset of each partition for that consumer group. This makes offsets essential for fault tolerance and smooth failover, making the system both, resilient and reliable.

### Compacted Logs

Normally, Kafka keeps every message in a topic for a configured amount of time (like 7 days). But Kafka uses another strategy called log compaction (instead of time-based retention) for some topics, like the special `__consumer_offsets` topic. In this strategy, instead of deleting messages after a time, it deletes old values for the same key, keeping just the most recent update.

This is how Kafka efficiently stores committed offsets in the the `__consumer_offsets` topic, that is, only the last committed offset is stored per consumer group per partition:
```
Key = consumer_group + topic + partition
Value = last committed offset
```

This keeps the topic from growing forever. We can configure any topic we create to be compacted this way by setting `cleanup.policy=compact`. This is great for things like:
- Inventory counts (latest stock per product)
- User profiles (latest info per user)
- Account balance (latest balance per account)

Under the hood, Kafka  periodically runs a compaction job in the background to compact topics. This job keeps only the most recent value for each key and deletes the older ones. If the latest value is null, it deletes the key entirely.

It's important to note that compaction is not the same as compression. Compaction removes old records for the same key, keeping only the latest and compression shrinks size of messages. They can be used together, but they solve different problems.

## Heartbeats in Kafka

The Group Coordinator is a Kafka broker that manages membership, heartbeat checking, partition assignments, and rebalancing for a specific consumer group. 









