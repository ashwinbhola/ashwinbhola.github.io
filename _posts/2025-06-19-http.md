---
layout: post
title: ""
subtitle: ""
tags: ["system-design"]
readtime: true
---

## HTTP2
**binary framing layer and multiplexing**:
- request has method line, header, data (data not in GET); response has method and data
- Instead of plain text (HTTP1), HTTP2 sends data in binary format (faster to understand for computers as it's the native language of their hardware)
- Each message split into a frame which consists of a frame header (9 bytes) and the frame payload
- Each frame belongs to a message and hence is labeled with a message Id (same as stream Id) -- a stream is like a container that is identified by a unique stream ID and carries frames related to a single HTTP exchange (request + response) => bidirectional flow over the same stream
- The binary framing layer is the set of rules for how to: Chop up the data, Label it, Send it, Rebuild it on the other end
- Using stream IDs, http2 can send multiple messages from one machine to another over the same connection (multiplexing)
Message 1 (StreamID = 1): frame 1, frame 2, frame 3 (bigger message)
Message 2 (StreamID = 2): frame 4, frame 5 (smaller message)
Over the same TCP connection, messages would be sent like frame 1, frame 4, frame 2, frame 5, frame 3 (hypothetical order) --  frames of multiple messages sent together and message 2 got delivered even before message 1 -- unline http1.1, message 2 didn't have to wait for the bigger message 1 to get delivered and responded to (no Head of line blocking at the application level; can still happen at the transport layer level with TCP data segments in http2 and http1)
- When the server recieves these messages, they'll put frame 1 and frame 2 together as they'll have the stream ID tagged to them (thanks to binary framing layer)
- In HTTP/2, everything is a frame; there exist different type of frames -- eg: Header frames (separate from frame's header) carries the request/response's header; DATA frames carry the request/response body; the size of a frame header is always 9 bytes but the size of its payload can vary in size
- Example of message and stream relation:
```
Imagine you're loading a webpage:

Your browser sends a request (message) for index.html.
➤ This goes into stream #1, which sends:

HEADERS frame (with request info like method, path)

Maybe a DATA frame (if there's a body)

The server replies with a response (another message).
➤ It uses the same stream #1 and sends:

HEADERS frame (status code, etc.)

DATA frames (HTML content split into chunks)

The request and response together share the same stream.
```

Thus, stream = Logical channel for a single request/response

- Each HTTP/2 frame has a 9-byte header, which includes:
Length
Type (HEADERS, DATA, etc.)
Flags (like END_STREAM, END_HEADERS)
Stream ID (which stream it belongs to)

END_HEADERS is set to 1 to tell the other machine that this is the last frame of message's header
END_STREAM is set to 1 when its the last fame from the sender

- A stream goes through several stages: Idle (Not used yet) -> Open (A request is being sent or received) -> Half-closed (Client is done sending, but the server isn’t) -> Closed (Both sides are done; no more frames can be sent on this stream)
```
Real-Life Example: Request for a Webpage
Client sends a request (on Stream #1):
Sends a HEADERS frame (with things like GET /index.html)
Maybe also DATA frames (if it’s a POST request with a body)
When done, it sends a flag called END_STREAM to say “I'm finished sending.”
🔁 Now the stream is half-closed (client side)

Server sends the response:
Sends HEADERS (like HTTP 200 OK)
Sends DATA frames with the actual HTML
Then it also sends END_STREAM flag
🔁 Now the stream is fully closed
```

**Stream prioritization**
- HTTP2 enables multiple streams to be active together

```
Imagine a web page: HTML (index.html), CSS (style.css), JavaScript (app.js), 10 images (img1.jpg, img2.jpg, etc.)
Even though all those requests can be active at the same time with HTTP2 multiplexing, we want:
HTML first (so the browser can parse the layout)
CSS and JS next (to render and interact)
Images last (they’re not critical for page structure)
```

- Stream prioritization is a mechanism that lets the client tell the server which streams are more important — so the server can allocate its resources smarter and faster to serve those streams at a priority. In the above example: Client can tell the server "Please send this HTML stream first — it's more important than the others"

- This is achieved by attaching an Optional Priority section to a HEADERS frame in a stream OR by sending a separate PRIORITY frame in each stream. This information (attached or sent separately)contains the following fields: 
Stream dependency ID (which streams is this stream dependent on), Weight (value between 1 to 256; decides the bandwidth the stream gets compared to its competitors), Exclusive Flag (tells the server to prioritize only this stream among all its competitors)

eg: 
Stream 3 = HTML (no dependency)
Stream 5 = CSS (depends on 3, weight 200, exclusive=1)
Stream 7 = Image (depends on 3, weight 40)
Stream 9 = Image (depends on 3, weight 10)

The server will process stream 3 first as everything else depends on it, then stream 5 (as exclusive = 1), then stream 7 and 9 are processed parallely but stream 7 gets 80% of the bandwidth of server while stream 9 gets 20%. Thus, streams form a dependency tree where each stream can depend on a parent and have child streams with different weights. 
Stream 3
└── Stream 5 (exclusive)
    ├── Stream 7
    └── Stream 9


**HPACK**
- In HTTP/1.1, headers are sent as plain text every time — even if they’re identical across requests. This is wastage of space.
- HPACK maintains 2 tables on both server and client side of recently used headers. When a header is reused, it can be sent by just referencing its index number in the table. This avoids sending the full header string again.
- eg: 
1st request: 
```
:method: GET
:path: /
user-agent: MyBrowser/1.0
```
2nd request:
```
:method: GET
:path: /search
user-agent: MyBrowser/1.0
```
For the second request, client will just have to send `:path: /search` (if a header isn't in the headers table, HPACK sends it using literal encoding — name + value) along with the index of `:method: GET` and `user-agent: MyBrowser/1.0` in the shared header table => Much smaller frame! Server decodes it by looking up the index numbers.

- what are the two tables? one is static (holds commonly used values of headers -- eg: method=Get, method=Post, scheme=https etc) and other is dynamic (starts empty and fills up as new headers are sent which are not in static table)

**Server push**
- HTTP/2 Server Push lets the server send resources to the client before the client requests them.
- In regular HTTP (even HTTP/2), the client must request everything. For example: Client asks for index.html -> Parses HTML, sees <link href="style.css">, and then asks for style.css -> More delay
- With Server Push: Server predicts that style.css will be needed
```
Client sends a request for a page, e.g. GET /index.html on stream 1

Server responds with:
A normal response on stream 1 (for index.html)
A PUSH_PROMISE frame (still on stream 1) saying: “Hey, I’m going to push /style.css on stream 2”

Server then sends:
Headers and data for /style.css on stream 2
```

Thus, PUSH_PROMISE frame is sent on client-initiated stream and then a new stream (server-initiated) carries the pushed resource

- The client can reject pushes (either per stream or via SETTINGS). Also, Server can’t force the browser to use the pushed content — the client may discard it as it may have the asset already cached (HTTP/2 server push is cache-aware and rejects the server sent assets if the client already has them cached)

- It was meant to reduce latency but is rarely used today due to complexity and poor results in real-world usage. Hard to predict what the client really needs; Wasted bandwidth if the client already has the resource cached

- HTTP/3 removed server push entirely


